---
layout: post
title:  "Robots and Humans"
date:   2019-11-18 16:07:00 +0100
categories: general
og_title: Robots and Humans
og_description: The robots.txt file contains instructions for search robots (or user-agents). In the file I can define which robots may or may not crawl which of my site directories and/or files.
og_type: website
og_image: /assets/img/og_image.jpg
---
The robots.txt file contains instructions for search robots (or user-agents). In the file I can define which robots may or may not crawl which of my 
site directories and/or files.

The way I configured my robots.txt is fairly simple since there are not many files or directories. I specified that all user-agents are allowed to 
crawl all of my web site, except for files with the file format .jpg or .gif, since I'm not interested in having any of my images turn up in web searches.

The humans.txt file contains information about the creators (human team) of the website, and it could also include technical information about the web site 
as well as thank you notes.

In my humans.txt file I included my own position (in regards to this web site) and name, the link to my Github account and my geolocation. I could have added 
more details like my social media accounts and e-mail, but I didn't feel like it. Then I added some basic technical information about the web site: last 
updated date, standards and that I used Jekyll.